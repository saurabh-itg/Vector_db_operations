{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4638ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['AZURE_OPENAI_KEY']=os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6142e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.getenv(\"AZURE_DEPLOYMENT_NAME\"), \n",
    "    api_version=os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "    api_key = os.getenv('AZURE_OPENAI_KEY'),  \n",
    "    temperature=0.9  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47364830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"France does not have an officially designated national food, as its culinary heritage is incredibly diverse and regional. However, **baguette**, **croissant**, and dishes like **pot-au-feu** are often considered iconic representations of French cuisine. \\n\\n### Key Examples:\\n1. **Baguette**: The French loaf is a cultural and culinary symbol of France, beloved for its crusty exterior and soft interior.\\n2. **Pot-au-Feu**: A traditional beef stew of slow-cooked meat and vegetables is often regarded as a staple comfort dish.\\n3. **Croissant**: The buttery, flaky pastry is internationally associated with French breakfast.\\n\\nFrench cuisine as a whole, with its emphasis on fresh ingredients, meticulous preparation, and balance of flavors, symbolizes the country's rich culinary identity.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 162, 'prompt_tokens': 15, 'total_tokens': 177, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-C3x2CXXtMQr2ZxGqngARNpRAGx7Le', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run--755a3b56-6437-4d6a-8d57-dd68885ec402-0', usage_metadata={'input_tokens': 15, 'output_tokens': 162, 'total_tokens': 177, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is the national food of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe1a426e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6792ae20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Yes! LangSmith is a sophisticated tool designed to enhance and refine the development, debugging, and evaluation of applications powered by large language models (LLMs). It is specifically tailored for developers who are building systems with tools like LangChain, and it helps monitor the behavior and performance of LLM-driven applications when handling complex chain workflows or agents.\\n\\n### Key Features of LangSmith:\\n1. **Tracing for Debugging**:\\n   - LangSmith enables developers to trace and visualize the exact paths and interactions that occur in LLM-based workflows. This is crucial for identifying bottlenecks, unexpected behavior, or failures in chains and agents.\\n\\n2. **Evaluation Framework**:\\n   - The platform provides tools to evaluate how well an LLM performs specific tasks. Developers can benchmark the model's responses against predefined criteria or use LangSmith to compare different prompts, chains, or agents.\\n\\n3. **Fine-Tuning Model Behaviors**:\\n   - It helps developers refine model outputs, ensuring that the models align with desired goals and handle edge cases effectively.\\n\\n4. **Integration with LangChain**:\\n   - LangSmith works seamlessly with LangChain, a popular framework for building applications powered by LLMs. It allows developers to connect their existing LangChain setups and immediately start debugging and optimizing workflows.\\n\\n5. **Dataset Creation and Experimentation**:\\n   - The platform enables developers to easily create datasets and run experiments using various prompts, chains, or models, streamlining the iterative development process.\\n\\n6. **Analytics and Insights**:\\n   - LangSmith provides analytics on LLM performance, including success rates, failure points, latency, and more. These metrics can guide decisions on improvements or optimizations.\\n\\n### Benefits of Using LangSmith:\\n1. **Improved Debugging Efficiency**:\\n   - The tracing tools save developers time by pinpointing issues in LLM workflows without needing manual intervention.\\n   \\n2. **Higher Quality Outputs**:\\n   - With its evaluation and analytics capabilities, developers can ensure their models produce better, more reliable results.\\n   \\n3. **Scalability**:\\n   - LangSmith is designed to handle complex workflows and large-scale applications, making it useful for projects that grow in scope over time.\\n\\n4. **Faster Iteration Cycles**:\\n   - Developers can test and tweak their systems quickly, accelerating progress toward delivering polished applications.\\n\\n### How to Get Started:\\nLangSmith is often used in conjunction with LangChain, but it should be compatible with other frameworks or direct LLM integrations as well. To use LangSmith:\\n1. Integrate your application workflows with LangSmith's API or toolkit.\\n2. Begin logging traces to visualize how your chains or agents behave during execution.\\n3. Use the evaluation tools to test performance and refine your setup.\\n\\nLangSmith is particularly valuable for developers who are working with complex AI systems and want to maximize efficiency, reliability, and results in their applications.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 583, 'prompt_tokens': 33, 'total_tokens': 616, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-C3x345EHrgkNPLyzLDlEyhUUgyHG4', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run--ab6de382-7b60-40ec-ae1d-1bbffdc2c1b6-0' usage_metadata={'input_tokens': 33, 'output_tokens': 583, 'total_tokens': 616, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc7b9daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af0b1d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! **LangSmith** is a developer tool created by **LangChain**, designed to help developers analyze, debug, and improve the performance of their language model applications (LLMs). It streamlines the process of observing, monitoring, and optimizing LLM-powered workflows and agents by enabling detailed tracking of inputs, outputs, errors, and overall runtime behavior. \n",
      "\n",
      "LangSmith is particularly useful for developers building with LangChain, as it provides them with advanced features like telemetry, evaluation capabilities, and experimentation with different configurations. It aims to address common challenges in working with LLM applications, such as debugging complex chains of prompts, identifying bottlenecks, and ensuring reliable execution.\n",
      "\n",
      "### Key Features of LangSmith:\n",
      "1. **Execution Tracing:**\n",
      "   - Tracks the execution flow of your LangChain applications, logging every step for better understanding.\n",
      "   - Visualizes the data flow, inputs, outputs, and intermediate states within chains and agents.\n",
      "\n",
      "2. **Debugging Tools:**\n",
      "   - Offers tools to debug issues in prompts, chains, or agents, enabling developers to quickly identify and fix problems.\n",
      "   - Detailed error analysis for failed runs and misaligned outputs.\n",
      "\n",
      "3. **Performance Monitoring:**\n",
      "   - Provides metrics on latency, success rates, and bottlenecks within your workflows.\n",
      "   - Helps optimize your application for faster and more accurate results.\n",
      "\n",
      "4. **Evaluation Framework:**\n",
      "   - Enables custom evaluation metrics to quantitatively assess the effectiveness of prompts or workflows.\n",
      "   - Facilitates A/B testing for different model configurations, system designs, or prompts.\n",
      "\n",
      "5. **Experimentation:**\n",
      "   - Makes it easier to test different prompt templates, chain structures, or agent setups to find the most performant or cost-effective configuration.\n",
      "\n",
      "6. **Central Dashboard:**\n",
      "   - A centralized interface for monitoring application performance, debugging issues, and iterating on designs.\n",
      "\n",
      "### Integration:\n",
      "LangSmith integrates seamlessly with LangChain workflows. Developers can instrument their chains and agents with LangSmith by adding a few configuration settings, and it works across various LLM providers like OpenAI, Anthropic, or others supported by LangChain.\n",
      "\n",
      "### Benefits:\n",
      "- Reduces the time spent troubleshooting and debugging.\n",
      "- Improves the reliability of complex LLM workflows.\n",
      "- Enhances transparency in how an application interacts with LLMs.\n",
      "- Gives actionable insights for optimization and scaling.\n",
      "\n",
      "In summary, LangSmith serves as a **\"developer copiloting infrastructure\"** for building high-quality, robust LLM applications. If you're working with LangChain or LLM-based systems, LangSmith can be an invaluable tool to ensure your workflows are efficient, error-resilient, and effective at scale.\n",
      "\n",
      "Let me know if you'd like help getting started with LangSmith!\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fdc290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
